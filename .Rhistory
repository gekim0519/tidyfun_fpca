INV.SIG[,,i] = inv.sig
LAMBDA.BW[i,] = lambda.bw
if(verbose) { if(round(i %% (N.iter/10)) == 0) {cat(".")} }
}
###############################################################
## compute posteriors for this dataset
###############################################################
## main effects
beta.post = array(NA, dim = c(p, D, (N.iter - N.burn)))
for(n in 1:(N.iter - N.burn)){
beta.post[,,n] = t(BW[,, n + N.burn]) %*% t(Theta)
}
beta.pm = apply(beta.post, c(1,2), mean)
beta.LB = apply(beta.post, c(1,2), quantile, c(.025))
beta.UB = apply(beta.post, c(1,2), quantile, c(.975))
## covariance matrix
sig.pm = solve(apply(INV.SIG, c(1,2), mean))
## export fitted values
fixef.pm = W.des %*% beta.pm
data = if(is.null(data)) { mf_fixed }  else { data }
ret = list(beta.pm, beta.UB, beta.LB, fixef.pm, mt_fixed, data)
names(ret) = c("beta.hat", "beta.UB", "beta.LB", "Yhat", "terms", "data")
class(ret) = "fosr"
ret
}
gibbs_cs_wish_ts(cca ~ pasat, data = DTI, Kt = 10)
help(Xt_siginv_X)
Xt_siginv_X = function(tx, siginv, y = NULL){
D = dim(siginv)[1]
I = dim(tx)[2] / D
if(is.null(y)){
ret.mat = matrix(0, nrow = dim(tx)[1], ncol = dim(tx)[1])
for(i in 1:I){
ind.cur = (D * (i - 1) + 1) : (D*i)
prod.cur = tx[,ind.cur] %*% siginv %*% t(tx[,ind.cur])
ret.mat = ret.mat + prod.cur
}
} else if(!is.null(y)){
ret.mat = matrix(0, nrow = dim(tx)[1], ncol = 1)
for(i in 1:I){
ind.cur = (D * (i - 1) + 1) : (D*i)
prod.cur = tx[,ind.cur] %*% siginv %*% y[ind.cur]
ret.mat = ret.mat + prod.cur
}
}
return(ret.mat)
}
gibbs_cs_wish_ts = function(formula, Kt=5, data=NULL, verbose = TRUE, N.iter = 5000, N.burn = 1000, alpha = .1,
min.iter = 10, max.iter = 50, Aw = NULL, Bw = NULL, v = NULL, SEED = NULL){
call <- match.call()
tf <- terms.formula(formula, specials = "re")
trmstrings <- attr(tf, "term.labels")
specials <- attr(tf, "specials")
where.re <-specials$re - 1
if (length(where.re) != 0) {
mf_fixed <- model.frame(tf[-where.re], data = data)
formula = tf[-where.re]
responsename <- attr(tf, "variables")[2][[1]]
###
REs = list(NA, NA)
REs[[1]] = names(eval(parse(text=attr(tf[where.re], "term.labels")), envir=data)$data)
REs[[2]]=paste0("(1|",REs[[1]],")")
###
formula2 <- paste(responsename, "~", REs[[1]], sep = "")
newfrml <- paste(responsename, "~", REs[[2]], sep = "")
newtrmstrings <- attr(tf[-where.re], "term.labels")
formula2 <- formula(paste(c(formula2, newtrmstrings),
collapse = "+"))
newfrml <- formula(paste(c(newfrml, newtrmstrings), collapse = "+"))
mf <- model.frame(formula2, data = data)
if (length(data) == 0) {
Z = lme4::mkReTrms(lme4::findbars(newfrml), fr = mf)$Zt
}
else {
Z = lme4::mkReTrms(lme4::findbars(newfrml), fr = data)$Zt
}
}
else {
mf_fixed <- model.frame(tf, data = data)
}
mt_fixed <- attr(mf_fixed, "terms")
# get response (Y)
Y <- model.response(mf_fixed, "numeric")
# x is a matrix of fixed effects
# automatically adds in intercept
X <- model.matrix(mt_fixed, mf_fixed, contrasts)
if(!is.null(SEED)) { set.seed(SEED) }
## fixed effect design matrix
W.des = X
I = dim(Y)[1]
p = dim(W.des)[2]
D = dim(Y)[2]
## bspline basis and penalty matrix
Theta = splines::bs(1:D, df=Kt, intercept=TRUE, degree=3)
diff0 = diag(1, D, D)
diff2 = matrix(rep(c(1,-2,1, rep(0, D-2)), D-2)[1:((D-2)*D)], D-2, D, byrow = TRUE)
P0 = t(Theta) %*% t(diff0) %*% diff0 %*% Theta
P2 = t(Theta) %*% t(diff2) %*% diff2 %*% Theta
P.mat = alpha * P0 + (1-alpha) * P2
## data organization; these computations only need to be done once
Y.vec = as.vector(t(Y))
t.designmat.X = t(kronecker(W.des, Theta))
sig.X = kronecker(t(W.des) %*% W.des, t(Theta)%*% Theta)
## initial estimation and hyperparameter choice
vec.BW = solve(kronecker(t(W.des)%*% W.des, t(Theta) %*% Theta)) %*% t(kronecker(W.des, Theta)) %*% Y.vec
mu.q.BW = matrix(vec.BW, Kt, p)
Yhat = as.matrix(W.des %*% t(mu.q.BW) %*% t(Theta))
if(is.null(v)){
fpca.temp = fpca.sc(Y = Y - Yhat, pve = .95, var = TRUE)
cov.hat = fpca.temp$efunctions %*% tcrossprod(diag(fpca.temp$evalues, nrow = length(fpca.temp$evalues),
ncol = length(fpca.temp$evalues)), fpca.temp$efunctions)
cov.hat = cov.hat + diag(fpca.temp$sigma2, D, D)
Psi = cov.hat * I
} else {
Psi = diag(v, D, D)
}
v = ifelse(is.null(v), I, v)
inv.sig = solve(Psi/v)
Aw = ifelse(is.null(Aw), Kt/2, Aw)
if(is.null(Bw)){
Bw = b.q.lambda.BW = sapply(1:p, function(u) max(1, .5*sum(diag( t(mu.q.BW[,u]) %*% P.mat %*% (mu.q.BW[,u])))))
} else {
Bw = b.q.lambda.BW = rep(Bw, p)
}
## matrices to store within-iteration estimates
BW = array(NA, c(Kt, p, N.iter))
BW[,,1] = bw = matrix(rnorm(Kt * p, 0, 10), Kt, p)
INV.SIG = array(NA, c(D, D, N.iter))
INV.SIG[,,1] = inv.sig = diag(10, D, D)
LAMBDA.BW = matrix(NA, nrow = N.iter, ncol = p)
LAMBDA.BW[1,] = lambda.bw = runif(p, .1, 10)
y.post = array(NA, dim = c(I, D, (N.iter - N.burn)))
if(verbose) { cat("Beginning Sampler \n") }
for(i in 1:N.iter){
###############################################################
## update b-spline parameters for fixed effects
###############################################################
sigma = solve(Xt_siginv_X(tx = t.designmat.X, siginv = inv.sig) +
kronecker(diag(lambda.bw), P.mat ))
mu = sigma %*% Xt_siginv_X(tx = t.designmat.X, siginv = inv.sig, y = Y.vec)
bw = matrix(MASS::mvrnorm(1, mu = mu, Sigma = sigma), nrow = Kt, ncol = p)
beta.cur = t(bw) %*% t(Theta)
###############################################################
## update inverse covariance matrix
###############################################################
resid.cur = Y - W.des %*% beta.cur
inv.sig = stats::rWishart(1, v + I, solve(Psi + t(resid.cur) %*% resid.cur))[,,1]
###############################################################
## update variance components
###############################################################
## lambda for beta's
for(term in 1:p){
a.post = Aw + Kt/2
b.post = Bw[term] + 1/2 * bw[,term] %*% P.mat %*% bw[,term]
lambda.bw[term] = rgamma(1, a.post, b.post)
}
###############################################################
## save this iteration's parameters
###############################################################
BW[,,i] = as.matrix(bw)
INV.SIG[,,i] = inv.sig
LAMBDA.BW[i,] = lambda.bw
if(verbose) { if(round(i %% (N.iter/10)) == 0) {cat(".")} }
}
###############################################################
## compute posteriors for this dataset
###############################################################
## main effects
beta.post = array(NA, dim = c(p, D, (N.iter - N.burn)))
for(n in 1:(N.iter - N.burn)){
beta.post[,,n] = t(BW[,, n + N.burn]) %*% t(Theta)
}
beta.pm = apply(beta.post, c(1,2), mean)
beta.LB = apply(beta.post, c(1,2), quantile, c(.025))
beta.UB = apply(beta.post, c(1,2), quantile, c(.975))
## covariance matrix
sig.pm = solve(apply(INV.SIG, c(1,2), mean))
## export fitted values
fixef.pm = W.des %*% beta.pm
data = if(is.null(data)) { mf_fixed }  else { data }
ret = list(beta.pm, beta.UB, beta.LB, fixef.pm, mt_fixed, data)
names(ret) = c("beta.hat", "beta.UB", "beta.LB", "Yhat", "terms", "data")
class(ret) = "fosr"
ret
}
gibbs_cs_wish_ts(cca ~ pasat, data = DTI, Kt = 10)
bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "Gibbs", cov.method = "FPCA", N.iter = 500, N.burn = 200)
Gibbs = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "Gibbs", cov.method = "FPCA", N.iter = 500, N.burn = 200)
Gibbs = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "Gibbs", cov.method = "FPCA", N.iter = 500, N.burn = 200)
## Gibbs Wishart
Gibbs_wish = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "Gibbs", cov.method = "Wishart", N.iter = 500, N.burn = 200)
gibbs_cs_fpca(cca ~ pasat, data = DTI, Kt = 10, N.iter = 500, N.burn = 200)
gibbs = gibbs_cs_fpca(cca ~ pasat, data = DTI, Kt = 10, N.iter = 500, N.burn = 200)
models = c("default", "VB", "Gibbs", "OLS", "GLS")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])
plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
gibbs = gibbs_cs_fpca(cca ~ pasat, data = DTI, Kt = 10, N.iter = 500, N.burn = 200)
models = c("Gibbs", "gibbs")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])
plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
Gibbs = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "Gibbs", cov.method = "FPCA", N.iter = 500, N.burn = 200)
models = c("Gibbs", "gibbs")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])
plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
gibbs_cs_fpca_tfd(cca ~ pasat, data = dti, Kt = 10, N.iter = 500, N.burn = 200)
source("../function/gibbs_cs_fpca_tfd.R")
source("../function/gibbs_cs_fpca_tfd.R")
source("../function/gibbs_cs_fpca_tfd.R")
source("../function/gibbs_cs_fpca_tfd.R")
source("../function/gibb_cs_fpca_tfd.R")
source("../function/gibbs_cs_fpca_tfd.R")
gibbs_cs_fpca_tfd(cca ~ pasat, data = dti, Kt = 10, N.iter = 500, N.burn = 200)
gibbs_dti = gibbs_cs_fpca_tfd(cca ~ pasat, data = dti, Kt = 10, N.iter = 500, N.burn = 200)
source("../function/gibbs_cs_fpca_tfd.R")
source("../function/gibbs_cs_fpca_tfd.R")
gibbs_dti = gibbs_cs_fpca_tfd(cca ~ pasat, data = dti, Kt = 10, N.iter = 500, N.burn = 200)
models = c("Gibbs", "gibbs", "gibbs_dti")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])
plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
Gibbs_bayes = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "Gibbs", cov.method = "FPCA", N.iter = 500, N.burn = 200)
gibbs = gibbs_cs_fpca(cca ~ pasat, data = DTI, Kt = 10, N.iter = 500, N.burn = 200)
models = c("Gibbs_bayes", "gibbs", "gibbs_dti")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])
plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
gibbs_dti = gibbs_cs_fpca_tfd(cca ~ pasat, data = dti, Kt = 10, N.iter = 500, N.burn = 200)
models = c("Gibbs_bayes", "gibbs", "gibbs_dti", gibbs_dti_wish)
gibbs_dti_wish = gibbs_cs_wish_tfd(cca ~ pasat, data = DTI, Kt = 10, N.iter = 500, N.burn = 200)
source("../function/gibbs_cs_fpca_wish_tfd.R")
source("../function/gibbs_cs_wish_tfd.R")
gibbs_dti_wish = gibbs_cs_wish_tfd(cca ~ pasat, data = DTI, Kt = 10, N.iter = 500, N.burn = 200)
gibbs_dti_wish = gibbs_cs_wish_tfd(cca ~ pasat, data = DTI, Kt = 10, N.iter = 500, N.burn = 200)
gibbs_dti_wish = gibbs_cs_wish_tfd(cca ~ pasat, data = DTI, Kt = 10, N.iter = 500, N.burn = 200)
gibbs_dti_wish = gibbs_cs_wish_tfd(cca ~ pasat, data = dti, Kt = 10, N.iter = 500, N.burn = 200)
models = c("Gibbs_bayes", "gibbs", "gibbs_dti", "gibbs_dti_wish")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])
plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
models = c("Gibbs_bayes", "gibbs", "gibbs_dti", "gibbs_dti_wish")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])
plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat
slopes
models = c("Gibbs_bayes", "gibbs", "gibbs_dti", "gibbs_dti_wish")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])
plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) +
geom_path() + theme_bw()
Gibbs_bayes = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "Gibbs", cov.method = "FPCA", N.iter = 500, N.burn = 200)
knitr::opts_chunk$set(echo = TRUE)
class(DTI$cca)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyfun)
library(refund)
library(ggplot2)
library(reshape2)
source("../function/quadWeights.R")
source("../function/fpca.tfd.R")
temp_tfd = load("../data/temp_tfd.RData")
handw_tfd= load("../data/handw_tfd.RData")
DTI = refund::DTI
dti = with(refund::DTI,
data.frame(id = ID, sex = sex,
case = factor(ifelse(case, "MS", "control")))) %>% as.tbl %>%
mutate(cca = tfd(DTI$cca, seq(0,1, l = 93), signif = 2) %>%
tfd(arg = seq(0,1,l = 93)),
rcst = tfd(DTI$rcst, seq(0, 1, l = 55), signif = 3))
fpca.tfd.ts <- function(data = NULL, col = NULL, Y.pred = NULL, argvals = NULL, random.int = FALSE,
nbasis = 10, pve = 0.99, npc = NULL, var = FALSE, simul = FALSE, sim.alpha = 0.95,
useSymm = FALSE, makePD = FALSE, center = TRUE, cov.est.method = 2, integration = "trapezoidal") {
col = enquo(col)
tfd = data %>%
pull(!! col)
stopifnot((!is.null(tfd)))
# stop if not: Y is not null and ydata is null or y is null and ydata is not null
# basically they both shouldnt be null
# change the tfd matrix into Y matrix
Y = tfd %>%
as.data.frame() %>%
spread(key = arg, value = value) %>%
select(-id) %>%
as.matrix()
if (is.null(Y.pred))
Y.pred = Y
D = NCOL(Y)
I = NROW(Y)
I.pred = NROW(Y.pred)
if (is.null(argvals))
argvals = seq(0, 1, length = D)
d.vec = rep(argvals, each = I)
id = rep(1:I, rep(D, I))
if (center) {
if (random.int) {
ri_data <- data.frame(y = as.vector(Y), d.vec = d.vec, id = factor(id))
gam0 = gamm4(y ~ s(d.vec, k = nbasis), random = ~(1 | id), data = ri_data)$gam
rm(ri_data)
} else gam0 = gam(as.vector(Y) ~ s(d.vec, k = nbasis))
mu = predict(gam0, newdata = data.frame(d.vec = argvals))
Y.tilde = Y - matrix(mu, I, D, byrow = TRUE)
} else {
Y.tilde = Y
mu = rep(0, D)
}
if (cov.est.method == 2) {
# smooth raw covariance estimate
cov.sum = cov.count = cov.mean = matrix(0, D, D)
for (i in 1:I) {
obs.points = which(!is.na(Y[i, ]))
cov.count[obs.points, obs.points] = cov.count[obs.points, obs.points] +
1
cov.sum[obs.points, obs.points] = cov.sum[obs.points, obs.points] + tcrossprod(Y.tilde[i,
obs.points])
}
G.0 = ifelse(cov.count == 0, NA, cov.sum/cov.count)
diag.G0 = diag(G.0)
diag(G.0) = NA
if (!useSymm) {
row.vec = rep(argvals, each = D)
col.vec = rep(argvals, D)
npc.0 = matrix(predict(gam(as.vector(G.0) ~ te(row.vec, col.vec, k = nbasis),
weights = as.vector(cov.count)), newdata = data.frame(row.vec = row.vec,
col.vec = col.vec)), D, D)
npc.0 = (npc.0 + t(npc.0))/2
} else {
use <- upper.tri(G.0, diag = TRUE)
use[2, 1] <- use[ncol(G.0), ncol(G.0) - 1] <- TRUE
usecov.count <- cov.count
usecov.count[2, 1] <- usecov.count[ncol(G.0), ncol(G.0) - 1] <- 0
usecov.count <- as.vector(usecov.count)[use]
use <- as.vector(use)
vG.0 <- as.vector(G.0)[use]
row.vec <- rep(argvals, each = D)[use]
col.vec <- rep(argvals, times = D)[use]
mCov <- gam(vG.0 ~ te(row.vec, col.vec, k = nbasis), weights = usecov.count)
npc.0 <- matrix(NA, D, D)
spred <- rep(argvals, each = D)[upper.tri(npc.0, diag = TRUE)]
tpred <- rep(argvals, times = D)[upper.tri(npc.0, diag = TRUE)]
smVCov <- predict(mCov, newdata = data.frame(row.vec = spred, col.vec = tpred))
npc.0[upper.tri(npc.0, diag = TRUE)] <- smVCov
npc.0[lower.tri(npc.0)] <- t(npc.0)[lower.tri(npc.0)]
}
} else if (cov.est.method == 1) {
# smooth y(s1)y(s2) values to obtain covariance estimate
row.vec = col.vec = G.0.vec = c()
cov.sum = cov.count = cov.mean = matrix(0, D, D)
for (i in 1:I) {
obs.points = which(!is.na(Y[i, ]))
temp = tcrossprod(Y.tilde[i, obs.points])
diag(temp) = NA
row.vec = c(row.vec, rep(argvals[obs.points], each = length(obs.points)))
col.vec = c(col.vec, rep(argvals[obs.points], length(obs.points)))
G.0.vec = c(G.0.vec, as.vector(temp))
# still need G.O raw to calculate to get the raw to get the diagonal
cov.count[obs.points, obs.points] = cov.count[obs.points, obs.points] +
1
cov.sum[obs.points, obs.points] = cov.sum[obs.points, obs.points] + tcrossprod(Y.tilde[i,
obs.points])
}
row.vec.pred = rep(argvals, each = D)
col.vec.pred = rep(argvals, D)
npc.0 = matrix(predict(gam(G.0.vec ~ te(row.vec, col.vec, k = nbasis)), newdata = data.frame(row.vec = row.vec.pred,
col.vec = col.vec.pred)), D, D)
npc.0 = (npc.0 + t(npc.0))/2
G.0 = ifelse(cov.count == 0, NA, cov.sum/cov.count)
diag.G0 = diag(G.0)
}
if (makePD) {
npc.0 <- {
tmp <- Matrix::nearPD(npc.0, corr = FALSE, keepDiag = FALSE, do2eigen = TRUE,
trace = TRUE)
as.matrix(tmp$mat)
}
}
### numerical integration for calculation of eigenvalues (see Ramsay & Silverman,
### Chapter 8)
w <- quadWeights(argvals, method = integration)
Wsqrt <- diag(sqrt(w))
Winvsqrt <- diag(1/(sqrt(w)))
V <- Wsqrt %*% npc.0 %*% Wsqrt
evalues = eigen(V, symmetric = TRUE, only.values = TRUE)$values
###
evalues = replace(evalues, which(evalues <= 0), 0)
npc = ifelse(is.null(npc), min(which(cumsum(evalues)/sum(evalues) > pve)), npc)
efunctions = matrix(Winvsqrt %*% eigen(V, symmetric = TRUE)$vectors[, seq(len = npc)],
nrow = D, ncol = npc)
evalues = eigen(V, symmetric = TRUE, only.values = TRUE)$values[1:npc]  # use correct matrix for eigenvalue problem
cov.hat = efunctions %*% tcrossprod(diag(evalues, nrow = npc, ncol = npc), efunctions)
### numerical integration for estimation of sigma2
T.len <- argvals[D] - argvals[1]  # total interval length
T1.min <- min(which(argvals >= argvals[1] + 0.25 * T.len))  # left bound of narrower interval T1
T1.max <- max(which(argvals <= argvals[D] - 0.25 * T.len))  # right bound of narrower interval T1
DIAG = (diag.G0 - diag(cov.hat))[T1.min:T1.max]  # function values
w2 <- quadWeights(argvals[T1.min:T1.max], method = integration)
sigma2 <- max(weighted.mean(DIAG, w = w2, na.rm = TRUE), 0)
####
D.inv = diag(1/evalues, nrow = npc, ncol = npc)
Z = efunctions
Y.tilde = Y.pred - matrix(mu, I.pred, D, byrow = TRUE)
Yhat = matrix(0, nrow = I.pred, ncol = D)
rownames(Yhat) = rownames(Y.pred)
colnames(Yhat) = colnames(Y.pred)
scores = matrix(NA, nrow = I.pred, ncol = npc)
VarMats = vector("list", I.pred)
for (i in 1:I.pred) VarMats[[i]] = matrix(NA, nrow = D, ncol = D)
diag.var = matrix(NA, nrow = I.pred, ncol = D)
crit.val = rep(0, I.pred)
for (i.subj in 1:I.pred) {
obs.points = which(!is.na(Y.pred[i.subj, ]))
if (sigma2 == 0 & length(obs.points) < npc)
stop("Measurement error estimated to be zero and there are fewer observed points than PCs; scores cannot be estimated.")
Zcur = matrix(Z[obs.points, ], nrow = length(obs.points), ncol = dim(Z)[2])
ZtZ_sD.inv = solve(crossprod(Zcur) + sigma2 * D.inv)
scores[i.subj, ] = ZtZ_sD.inv %*% t(Zcur) %*% (Y.tilde[i.subj, obs.points])
Yhat[i.subj, ] = t(as.matrix(mu)) + scores[i.subj, ] %*% t(efunctions)
if (var) {
VarMats[[i.subj]] = sigma2 * Z %*% ZtZ_sD.inv %*% t(Z)
diag.var[i.subj, ] = diag(VarMats[[i.subj]])
if (simul & sigma2 != 0) {
norm.samp = mvrnorm(2500, mu = rep(0, D), Sigma = VarMats[[i.subj]])/matrix(sqrt(diag(VarMats[[i.subj]])),
nrow = 2500, ncol = D, byrow = TRUE)
crit.val[i.subj] = quantile(apply(abs(norm.samp), 1, max), sim.alpha)
}
}
}
ret.objects = c("Yhat", "Y", "scores", "mu", "efunctions", "evalues", "npc",
"argvals")
if (var) {
ret.objects = c(ret.objects, "sigma2", "diag.var", "VarMats")
if (simul)
ret.objects = c(ret.objects, "crit.val")
}
ret = lapply(1:length(ret.objects), function(u) get(ret.objects[u]))
names(ret) = ret.objects
class(ret) = "fpca"
return(ret)
}
fit.cca = fpca.tfd.ts(data = dti, col = rcst)
fit.cca = fpca.tfd.ts(data = dti, col = rcst)
fit.mu = data.frame(mu = fit.cca$mu,
n = 1:ncol(fit.cca$Yhat))
fit.basis = data.frame(phi = fit.cca$efunctions, #the FPC basis functions.
n = 1:ncol(fit.cca$Yhat))
## plot estimated mean function
ggplot(fit.mu, aes(x = n, y = mu)) + geom_path()
## plot the first two estimated basis functions
fit.basis.m = melt(fit.basis, id = 'n')
ggplot(subset(fit.basis.m, variable %in% c('phi.1', 'phi.2')), aes(x = n,
y = value, group = variable, color = variable)) + geom_path()
gam0 = gamm4::gamm4(y ~ s(d.vec, k = nbasis), random = ~(1 | id), data = ri_data)$gam
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyfun)
library(refund)
library(ggplot2)
library(reshape2)
source("../function/quadWeights.R")
source("../function/fpca.tfd.R")
temp_tfd = load("../data/temp_tfd.RData")
handw_tfd= load("../data/handw_tfd.RData")
DTI = refund::DTI
dti = with(refund::DTI,
data.frame(id = ID, sex = sex,
case = factor(ifelse(case, "MS", "control")))) %>% as.tbl %>%
mutate(cca = tfd(DTI$cca, seq(0,1, l = 93), signif = 2) %>%
tfd(arg = seq(0,1,l = 93)),
rcst = tfd(DTI$rcst, seq(0, 1, l = 55), signif = 3))
